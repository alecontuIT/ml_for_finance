{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "# Chatbots digital assistant\n",
    "\n",
    "**Chatbots** are computer programs that maintain a conversation with a user in natural language. They can understand the user’s intent and send responses. These chatbots use deep learning and NLP to process language, enabling them to understand human speech. Banking bots enable consumers to check their balance, transfer money, pay bills, and more. Brokering bots enable consumers to find investment options, make investments, and track balances. Customer support bots provide instant responses, dramatically increasing customer satisfaction.\n",
    "Depending on the way bots are programmed, we can categorize chatbots into two variants:\n",
    "- Rule-based: this variety of chatbots is trained according to rules. These chatbots do not learn through interactions and may sometimes fail to answer complex queries outside of the defined rules.\n",
    "- Self-learning: this variety of bots relies on ML and AI technologies to converse with users. Self-learning chatbots are further divided into\n",
    " - Retrieval-based: are trained to rank the best response from a finite set of predefined responses.\n",
    " - Generative: are not built with predefined responses. They are trained using a large number of previous conversations. They require a very large amount of conversational data to train.\n",
    " \n",
    " \n",
    "The goal of this case study is to build a basic prototype of a conversational chatbot powered by NLP. Such chatbots are designed to quickly retrieve the details about a stock or an instrument that may help the user make a trading decision. The chatbot could also engage in casual con‐ versations with a user, perform basic mathematical calculations, and provide answers to questions from a list used to train it. The chatbot prototype created in this case study is designed to understand user inputs and intention and retrieve the information they are seeking. It is a small prototype that could be enhanced for use as an information retrieval bot in banking, brokering, or customer support.\n",
    "\n",
    "We will use two text-based libraries: *spaCy* and *ChatterBot*. ChatterBot is a Python library used to create simple chatbots with minimal programming required. An untrained instance of ChatterBot starts off with no knowledge of how to communicate. Each time a user enters a statement, the library saves the input and response text. As ChatterBot receives more inputs, the number of responses it can offer and the accuracy of those responses increase. The program selects the response by searching for the closest matching known statement to the input. It then returns the most likely response to that statement based on how frequently each response is issued by the people the bot communicates with.\n",
    "\n",
    "**IN MY OPINION NOWADAYS WITH LLMs AS CHAT-GPT, LLAMA, BARD AND SO ON, THESE KIND OF CHATBOT ARE NO MORE USEFUL AND DO NOT WORK WELL. I WOULD SUGGEST TO SKIP THIS NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import pip\n",
    "installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "if 'chatterbot' not in installedPackages :\n",
    "    !pip install --use-pep517 ChatterBot==1.0.4   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the chatterbot package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from chatterbot import ChatBot\n",
    "from chatterbot.logic import LogicAdapter\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a default chatbot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to build a chatbot for customised function avilable in chatterbot. Chatterbot and many other chatbot packages comes with a data utility module that can be used to train the chatbots:\n",
    "- **Logic adapters**: determine the logic for how ChatterBot selects a response to a given input statement. We are using two inbuilt adapters: Best‐ Match, which returns the best known responses, and MathematicalEvaluation, which performs mathematical operations.\n",
    "- **Preprocessors**: are simple functions that modify the input statement a chatbot receives before the statement gets processed by the logic adapter. The preprocessors can be customized to perform different preprocessing steps, such as tokenization and lemmatization, in order to have clean and processed data. We use a preprocessor for cleaning white spaces, clean_whitespace.\n",
    "- **Corpus training**: we use the already existing corpuses english, english.greetings, and english.conversations for training the chatbot.\n",
    "- **List training**: we train the chatbot with the conversations that can be used for training using ListTrainer. The chatbot can be trained using a sig‐ nificant amount of conversation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [######              ] 32%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "chatB = ChatBot(\"Trader\",\n",
    "                preprocessors=['chatterbot.preprocessors.clean_whitespace'],\n",
    "                logic_adapters=['chatterbot.logic.BestMatch',\n",
    "                                'chatterbot.logic.MathematicalEvaluation'])\n",
    "\n",
    "# Corpus Training\n",
    "trainerCorpus = ChatterBotCorpusTrainer(chatB)\n",
    "\n",
    "#Train based on English Corpus\n",
    "trainerCorpus.train(\n",
    "    \"chatterbot.corpus.english\"\n",
    ")\n",
    "# Train based on english greetings corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.greetings\")\n",
    "\n",
    "# Train based on the english conversations corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.conversations\")\n",
    "\n",
    "trainerConversation = ListTrainer(chatB)\n",
    "#Traing based on conversations\n",
    "\n",
    "#List training\n",
    "trainerConversation.train([\n",
    "    'Help!',\n",
    "    'Please go to google.com',\n",
    "    'What is Bitcoin?',\n",
    "    'It is a decentralized digital currency'\n",
    "])\n",
    "\n",
    "# You can train with a second list of data to add response variations\n",
    "trainerConversation.train([\n",
    "    'What is Bitcoin?',\n",
    "    'Bitcoin is a cryptocurrency.'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(quit=\"quit\"):\n",
    "    user_input = \"\"\n",
    "    while user_input != quit:\n",
    "        user_input = quit\n",
    "        try:\n",
    "            user_input = input(\">\")\n",
    "        except EOFError:\n",
    "            print(user_input)\n",
    "        if user_input:\n",
    "            while user_input[-1] in \"!.\":\n",
    "                user_input = user_input[:-1]\n",
    "            print(chatB.get_response(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hi\n",
      "How are you doing?\n",
      ">well\n",
      "I'm also good.\n",
      ">What is 500 plus 1\n",
      "500 plus 1 = 501\n",
      ">what is an euro\n",
      "dollar: unit of currency in the united states.\n",
      ">lol ok. what is bitcoin?\n",
      "It is a decentralized digital currency\n",
      ">quit\n",
      "That's good to hear.\n"
     ]
    }
   ],
   "source": [
    "converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see a fairly good chatbot which gives us response according to the input that we have given. The first two responses are due to the training on english greetings and conversation corpus. Additionally the response to \"what is a dollar\" are due to the training on the english corpus. The sum computation is the result of the chatbot being trained on the Mathematical Evaluation logical adapter. The response to \"What is a bitcoin\" are the result of the customised list trainers. \n",
    "\n",
    "Given, that we have already have a customised chatbot, we move on to create a chatbot which is designed to give us the financial ratios of a company based on a customised logical adapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for customized chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of performing the data preparation is to use it for training through logic adapter.The details are under https://chatterbot.readthedocs.io/en/stable/logic/create-a-logic-adapter.html. Given the logic adapter need to be in a separate file from the chat bot, we perform the step of data preparation in the module **financial_ratio_adapter.py** where logic adapter is created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we combine all the components (i.e. preprocessor, custom logical adapter, list and corpus trainer) with the custom logical adapter (financial_ratio_adapter.FinancialRatioAdapter) that we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandrocontu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "#Here we add \n",
    "chatbot = ChatBot(\n",
    "    \"My ChatterBot\",\n",
    "    preprocessors=['chatterbot.preprocessors.clean_whitespace'],\n",
    "    logic_adapters=[\n",
    "        'financial_ratio_adapter.FinancialRatioAdapter',\n",
    "        'chatterbot.logic.MathematicalEvaluation',\n",
    "        'chatterbot.logic.BestMatch'\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Train based on English Corpus\n",
    "trainerCorpus.train(\n",
    "    \"chatterbot.corpus.english\"\n",
    ")\n",
    "# Train based on english greetings corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.greetings\")\n",
    "\n",
    "# Train based on the english conversations corpus\n",
    "trainerCorpus.train(\"chatterbot.corpus.english.conversations\")\n",
    "\n",
    "trainerConversation = ListTrainer(chatB)\n",
    "#Traing based on conversations\n",
    "\n",
    "trainerConversation.train([\n",
    "    'Help!',\n",
    "    'Please go to google.com',\n",
    "    'What is Bitcoin?',\n",
    "    'It is a decentralized digital currency'\n",
    "])\n",
    "\n",
    "# You can train with a second list of data to add response variations\n",
    "trainerConversation.train([\n",
    "    'What is Bitcoin?',\n",
    "    'Bitcoin is a cryptocurrency.'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the training was not only for the FinancialRatioAdapter, but also for the list and corpus trainer. Let us move to the model testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(quit=\"quit\"):\n",
    "    user_input = \"\"\n",
    "    while user_input != quit:\n",
    "        user_input = quit\n",
    "        try:\n",
    "            user_input = input(\">\")\n",
    "        except EOFError:\n",
    "            print(user_input)\n",
    "        if user_input:\n",
    "            while user_input[-1] in \"!.\":\n",
    "                user_input = user_input[:-1]\n",
    "            print(chatbot.get_response(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Get me the ROE of APPLE\n",
      "Sorry! Could not figure out what the user wants\n",
      ">get me the ROE of Apple\n",
      "Sorry! Could not figure out what the user wants\n",
      ">Get me the ROE of Citi\n",
      "https://www.zacks.com/stock/chart/C/fundamental/return-on-equity-ttm\n",
      "\t\t\t\t\t  \n",
      ">Get me the Price to equity of AAPL\n",
      "Sorry! Could not figure out what the user wants\n",
      ">quit\n",
      "Sorry! Could not figure out what the user wants\n"
     ]
    }
   ],
   "source": [
    "converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom logic adaptor for our Chatter bot, finds a RATIO or a COMPANY in the sentence using our NLP model. If the model finds exactly one COMPANY and exactly one RATIO, it con structs a url to guide the user. Additionally other logical adpater such as mathematical evaluation, and curpus and list trainer work as expected as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "In this case study, we have learned how to make a chatbot in python using the ChatterBot library. We learnt how to build a custom NLP based model focusing on NER(Named Entity Recognition) and use in a chatbot.\n",
    "\n",
    "\n",
    "In order to train a blank model, one must have a substantial training dataset. In this\n",
    "case study, we looked at patterns available to us and used them to generate training\n",
    "samples. \n",
    "\n",
    "This case study is a demo project, and significant enhancements can be made for each\n",
    "component to extend it for a wide variety of tasks. Additional preprocessing steps can\n",
    "be added to have cleaner data to work with. \n",
    "\n",
    "Overall, this case study provides an introduction to all the aspects of chatbot development. Although, it is a very simple bot, it’s a good starting point to use NLP to create\n",
    "chatbots.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
